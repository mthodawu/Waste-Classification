{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %pip install keras-tuner\n",
    "# %pip install tensorflow-addons  # For extra metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import InceptionV3, MobileNetV3Small\n",
    "from tensorflow.keras import layers, models\n",
    "from keras_tuner import HyperModel\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_addons as tfa  # Additional metrics\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Enable mixed precision training\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Define the hypermodel\n",
    "class WasteClassificationHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "    \n",
    "    def build(self, hp):\n",
    "        # Choose the model\n",
    "        model_type = hp.Choice('model_type', ['InceptionV3', 'MobileNetV3', 'DenseNet201'])\n",
    "        if model_type == 'InceptionV3':\n",
    "            base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        elif model_type == 'DenseNet201':\n",
    "            base_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        else:\n",
    "            base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=self.input_shape)\n",
    "        \n",
    "        # Freeze the base model\n",
    "        base_model.trainable = False\n",
    "        \n",
    "        # Define the model\n",
    "        model = models.Sequential([\n",
    "            base_model,\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(hp.Int('units', min_value=32, max_value=512, step=32), activation='relu'),\n",
    "            layers.Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1)),\n",
    "            layers.Dense(self.num_classes, activation='softmax', dtype='float32')  # Final layer with float32 precision\n",
    "        ])\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy', tfa.metrics.F1Score(num_classes=self.num_classes, average='macro'), 'Precision', 'Recall']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Define the data generator with augmentation and train-validation-test split\n",
    "def create_data_generators(hp, dataset_directory):\n",
    "    augmentation_technique = hp.Choice('augmentation_technique', ['none', 'flip', 'rotation', 'zoom'])\n",
    "    \n",
    "    if augmentation_technique == 'flip':\n",
    "        datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "    elif augmentation_technique == 'rotation':\n",
    "        datagen = ImageDataGenerator(rotation_range=20)\n",
    "    elif augmentation_technique == 'zoom':\n",
    "        datagen = ImageDataGenerator(zoom_range=0.2)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator()\n",
    "\n",
    "    # Split the data into train, validation, and test sets\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        os.path.join(dataset_directory, 'train'),\n",
    "        target_size=(224, 224),\n",
    "        batch_size=hp.Int('batch_size', min_value=16, max_value=64, step=16),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        os.path.join(dataset_directory, 'validation'),\n",
    "        target_size=(224, 224),\n",
    "        batch_size=hp.Int('batch_size', min_value=16, max_value=64, step=16),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        os.path.join(dataset_directory, 'test'),\n",
    "        target_size=(224, 224),\n",
    "        batch_size=hp.Int('batch_size', min_value=16, max_value=64, step=16),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "# Redirect console output to a file\n",
    "log_file = 'console_output_small.log'\n",
    "sys.stdout = open(log_file, 'w')\n",
    "\n",
    "# Define a custom callback to capture accuracy at each epoch\n",
    "class AccuracyLogger(Callback):\n",
    "    def __init__(self, log_file):\n",
    "        super().__init__()\n",
    "        self.log_file = log_file\n",
    "        # Open the log file in write mode\n",
    "        with open(self.log_file, 'w') as f:\n",
    "            f.write('Epoch,Accuracy,Validation Accuracy\\n')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        accuracy = logs.get('accuracy')\n",
    "        val_accuracy = logs.get('val_accuracy')\n",
    "\n",
    "        # Write the epoch, accuracy, and validation accuracy to the log file\n",
    "        with open(self.log_file, 'a') as f:\n",
    "            f.write(f\"{epoch+1},{accuracy},{val_accuracy}\\n\")\n",
    "\n",
    "# Define the dataset directory and number of classes\n",
    "dataset_directory = '/app/data/Datasets/Trashnet-resized'  # Update this path as necessary\n",
    "num_classes = 6  # Set the number of classes\n",
    "\n",
    "# Input shape\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# log file for accuracy\n",
    "log_file = 'accuracy_log1.csv'\n",
    "\n",
    "# Create the hypermodel\n",
    "hypermodel = WasteClassificationHyperModel(input_shape, num_classes)\n",
    "\n",
    "# Define the tuner\n",
    "tuner = RandomSearch(\n",
    "    hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='tuning_results',\n",
    "    project_name='waste_classification'\n",
    ")\n",
    "\n",
    "# Define the search space and perform tuning\n",
    "train_generator, validation_generator, test_generator = create_data_generators(tuner.oracle.hyperparameters, dataset_directory)\n",
    "tuner.search(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[AccuracyLogger(log_file), EarlyStopping(patience=2)]\n",
    ")\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Print the summary of the best model\n",
    "best_model.summary()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_f1, test_precision, test_recall = best_model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test F1 Score: {test_f1}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "\n",
    "# Close the log file to ensure all output is written\n",
    "sys.stdout.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
