{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install tensorflow\n",
    "%pip install opencv-python --upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation_array -> User can choose what transformations to apply. Simply comment/uncomment (#) the row corresponding to the transformation name.\n",
    "# enable_show -> User can choose to display (True) or none (False) the transformations applied to original images. Enabling this option, the execution speed will be reduced.\n",
    "\n",
    "transformation_array = [\n",
    "                        \"horizontalFlip\",\n",
    "                        \"verticalFlip\",\n",
    "                        \"rotation\",\n",
    "                        \"widthShift\",\n",
    "                        \"heightShift\"\n",
    "                        # ,\n",
    "                        # \"shearRange\",\n",
    "                        # \"zoom\",\n",
    "                        # \"blur\",\n",
    "                        # \"brightness\",\n",
    "                        # \"contrast\",\n",
    "                        # \"saturation\",\n",
    "                        # \"hue\",\n",
    "                        # \"gamma\"\n",
    "                        ];\n",
    "enable_show = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 15:36:00.191550: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-17 15:36:00.200500: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 15:36:00.211526: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 15:36:00.214763: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 15:36:00.222602: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/data/Datasets/ metal_and_other/metal/\n",
      "/app/data/Datasets/ augmented_metal_and_other/metal/\n",
      "Processing metal class.\n",
      "\n",
      "Successfully created the directory /app/data/Datasets/ augmented_metal_and_other/metal/\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/app/data/Datasets/ metal_and_other/metal/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully created the directory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m output_path)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;66;03m# Copy the original image in the new dataset\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     original_file_path \u001b[38;5;241m=\u001b[39m input_path \u001b[38;5;241m+\u001b[39m filename\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/app/data/Datasets/ metal_and_other/metal/'"
     ]
    }
   ],
   "source": [
    "# The new dataset 'augmented_waste_dataset' will be created.\n",
    "# This dataset contains the augmented images create by the ImageGenerator class and the orginal images,\n",
    "# in order to obtain an expanded version of the orginal dataset ready-to-use\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import os\n",
    "from numpy import expand_dims\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def blur(img):\n",
    "    return (cv2.blur(img,(30,30)))\n",
    "\n",
    "def horizontal_flip(img):\n",
    "    return (tf.image.flip_left_right(img))\n",
    "\n",
    "def vertical_flip(img):\n",
    "    return (tf.image.flip_up_down(img))\n",
    "\n",
    "def contrast(img):\n",
    "    return (tf.image.adjust_contrast(img, 0.5))\n",
    "\n",
    "def saturation(img):\n",
    "    return (tf.image.adjust_saturation(img, 3))\n",
    "\n",
    "def hue(img):\n",
    "    return (tf.image.adjust_hue(img, 0.1))\n",
    "\n",
    "def gamma(img):\n",
    "    return (tf.image.adjust_gamma(img, 2))\n",
    "\n",
    "# modified dataset source: starting with 100 images\n",
    "classes = ['metal', 'other']\n",
    "dataset_name = f'{classes[0]}_and_{classes[1]}'\n",
    "new_dataset = f'augmented_{classes[0]}_and_{classes[1]}' \n",
    "for class_tag in classes:\n",
    "  input_path = '/app/data/Datasets/ ' + dataset_name + '/' + class_tag + '/'\n",
    "  output_path = '/app/data/Datasets/' + new_dataset + '/' + class_tag + '/'\n",
    "  print(input_path)\n",
    "  print(output_path)\n",
    "#   # TMP\n",
    "#   !rm -rf $output_path\n",
    "#   # END TMP\n",
    "  # Skip augmentation for 'other' class\n",
    "  \n",
    "\n",
    "  print(f\"Processing {class_tag} class.\\n\")\n",
    "\n",
    "  try:\n",
    "    if not os.path.exists(output_path):\n",
    "      os.makedirs(output_path)\n",
    "  except OSError:\n",
    "      print (\"Creation of the directory %s failed\\n\\n\" % output_path)\n",
    "  else:\n",
    "      print (\"Successfully created the directory %s\\n\\n\" % output_path)\n",
    "\n",
    "  for filename in os.listdir(input_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "      # Copy the original image in the new dataset\n",
    "      original_file_path = input_path + filename\n",
    "      original_newname_file_path = output_path + Path(filename).stem + \"_original.jpg\"\n",
    "      %cp $original_file_path $original_newname_file_path\n",
    "      # Initialising the ImageDataGenerator class.\n",
    "      # We will pass in the augmentation parameters in the constructor.\n",
    "      if class_tag == 'other':\n",
    "       print(f\"Skipping augmentation for {class_tag} class.\\n\")\n",
    "       continue\n",
    "      for transformation in transformation_array:\n",
    "        if transformation == \"horizontalFlip\":\n",
    "              #datagen = ImageDataGenerator(horizontal_flip = True)                 # for random flip\n",
    "              datagen = ImageDataGenerator(preprocessing_function=horizontal_flip)  # all imgs flipped\n",
    "        elif transformation == \"verticalFlip\":\n",
    "              #datagen = ImageDataGenerator(vertical_flip = True)                   # for random flip\n",
    "              datagen = ImageDataGenerator(preprocessing_function=vertical_flip)    # all imgs flipped\n",
    "        elif transformation == \"rotation\":\n",
    "              datagen = ImageDataGenerator(rotation_range = 40, fill_mode='nearest')\n",
    "        elif transformation == \"widthShift\":\n",
    "              datagen = ImageDataGenerator(width_shift_range = 0.2, fill_mode='nearest')\n",
    "        elif transformation == \"heightShift\":\n",
    "              datagen = ImageDataGenerator(height_shift_range = 0.2, fill_mode='nearest')\n",
    "        elif transformation == \"shearRange\":\n",
    "              datagen = ImageDataGenerator(shear_range = 0.2)\n",
    "        elif transformation == \"zoom\":\n",
    "              datagen = ImageDataGenerator(zoom_range = [0.5, 1.0])\n",
    "        elif transformation == \"blur\":\n",
    "              datagen = ImageDataGenerator(preprocessing_function=blur)\n",
    "        elif transformation == \"brightness\":\n",
    "              #Values less than 1.0 darken the image, e.g. [0.5, 1.0],\n",
    "              #whereas values larger than 1.0 brighten the image, e.g. [1.0, 1.5],\n",
    "              #where 1.0 has no effect on brightness.\n",
    "              datagen = ImageDataGenerator(brightness_range = [1.1, 1.5])\n",
    "        elif transformation == \"contrast\":\n",
    "              datagen = ImageDataGenerator(preprocessing_function=contrast)\n",
    "        elif transformation == \"saturation\":\n",
    "              datagen = ImageDataGenerator(preprocessing_function=saturation)\n",
    "        elif transformation == \"hue\":\n",
    "              datagen = ImageDataGenerator(preprocessing_function=hue)\n",
    "        elif transformation == \"gamma\":\n",
    "              datagen = ImageDataGenerator(preprocessing_function=gamma)\n",
    "\n",
    "        # Loading a sample image and convert to RGB if not already RGB\n",
    "        img = load_img(input_path + filename)\n",
    "\n",
    "        # Converting the input sample image to an array\n",
    "        data = img_to_array(img)\n",
    "        # Reshaping the input image expand dimension to one sample\n",
    "        samples = expand_dims(data, 0)\n",
    "        # Plot original image\n",
    "      #   print(\"Original image:\")\n",
    "      #   print(filename)\n",
    "        if enable_show:\n",
    "          plt.imshow(img)\n",
    "          plt.show()\n",
    "          print(\"\\n\\n\")\n",
    "\n",
    "        # Generating and saving n_augmented_images augmented samples\n",
    "        print(\"Apply \" + transformation + \".\")\n",
    "        # prepare iterator\n",
    "        it = datagen.flow(samples, batch_size = 1,\n",
    "                    save_to_dir = output_path,\n",
    "                    save_prefix = Path(filename).stem + \"_\" + transformation,\n",
    "                    save_format ='jpg')\n",
    "        batch = next(it)    #corrected from batch = it.next()\n",
    "        # Plot trasnformed image\n",
    "        image = batch[0].astype('uint8')\n",
    "        if enable_show:\n",
    "          print(\"Transformed image:\")\n",
    "          plt.imshow(image)\n",
    "          plt.show()\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "print(\"Done!\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
