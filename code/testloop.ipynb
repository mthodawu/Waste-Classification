{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn\n",
    "# %pip install tensorflow\n",
    "# %pip install seaborn matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 12:24:43.120455: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-07 12:24:43.130293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-07 12:24:43.141360: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-07 12:24:43.144686: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-07 12:24:43.153700: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3447 images belonging to 2 classes.\n",
      "Found 861 images belonging to 2 classes.\n",
      "Found 4308 images belonging to 2 classes.\n",
      "Found 3032 images belonging to 2 classes.\n",
      "Found 1020 images belonging to 2 classes.\n",
      "Found 1019 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728303885.268942    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.273662    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.273835    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.274513    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.274609    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.274671    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.324299    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.324415    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1728303885.324483    2169 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-07 12:24:45.324548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3478 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728303896.919368    2322 service.cc:146] XLA service 0x70eb740030f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1728303896.919392    2322 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1050 Ti, Compute Capability 6.1\n",
      "2024-10-07 12:24:57.361663: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-07 12:24:59.416567: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8906\n",
      "2024-10-07 12:25:11.361789: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.53GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/11\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:41\u001b[0m 34s/step - accuracy: 0.5000 - loss: 0.7942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728303921.566155    2322 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5346 - loss: 0.7560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 12:25:49.407709: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.51GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 4s/step - accuracy: 0.5355 - loss: 0.7558 - val_accuracy: 0.5990 - val_loss: 0.6545\n",
      "Epoch 2/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - accuracy: 0.6160 - loss: 0.6882 - val_accuracy: 0.7284 - val_loss: 0.5645\n",
      "Epoch 3/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 839ms/step - accuracy: 0.6768 - loss: 0.5899 - val_accuracy: 0.7833 - val_loss: 0.4999\n",
      "Epoch 4/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 839ms/step - accuracy: 0.7208 - loss: 0.5263 - val_accuracy: 0.7304 - val_loss: 0.5055\n",
      "Epoch 5/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840ms/step - accuracy: 0.7441 - loss: 0.5216 - val_accuracy: 0.8147 - val_loss: 0.4538\n",
      "Epoch 6/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.8089 - loss: 0.4738 - val_accuracy: 0.8235 - val_loss: 0.4209\n",
      "Epoch 7/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.7661 - loss: 0.4861 - val_accuracy: 0.8363 - val_loss: 0.4186\n",
      "Epoch 8/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.7378 - loss: 0.5110 - val_accuracy: 0.8461 - val_loss: 0.3959\n",
      "Epoch 9/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840ms/step - accuracy: 0.7515 - loss: 0.4969 - val_accuracy: 0.8529 - val_loss: 0.3868\n",
      "Epoch 10/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.8146 - loss: 0.4013 - val_accuracy: 0.8569 - val_loss: 0.3911\n",
      "Epoch 11/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840ms/step - accuracy: 0.7799 - loss: 0.3941 - val_accuracy: 0.8520 - val_loss: 0.3618\n",
      "Epoch 12/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.8366 - loss: 0.3600 - val_accuracy: 0.8676 - val_loss: 0.3650\n",
      "Epoch 13/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9235 - loss: 0.3084 - val_accuracy: 0.8676 - val_loss: 0.3704\n",
      "Epoch 14/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8925 - loss: 0.3139 - val_accuracy: 0.8735 - val_loss: 0.3403\n",
      "Epoch 15/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8450 - loss: 0.3192 - val_accuracy: 0.8618 - val_loss: 0.3748\n",
      "Epoch 16/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840ms/step - accuracy: 0.9030 - loss: 0.3211 - val_accuracy: 0.8618 - val_loss: 0.3681\n",
      "Epoch 17/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 839ms/step - accuracy: 0.8530 - loss: 0.3371 - val_accuracy: 0.8843 - val_loss: 0.3152\n",
      "Epoch 18/100\n",
      "\u001b[1m 3/11\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.8056 - loss: 0.4441"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 12:28:35.782202: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-10-07 12:28:35.782423: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 750ms/step - accuracy: 0.8409 - loss: 0.4030 - val_accuracy: 0.8804 - val_loss: 0.3140\n",
      "Epoch 19/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8143 - loss: 0.3962 - val_accuracy: 0.8735 - val_loss: 0.3403\n",
      "Epoch 20/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9441 - loss: 0.2706 - val_accuracy: 0.8814 - val_loss: 0.3156\n",
      "Epoch 21/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 836ms/step - accuracy: 0.8882 - loss: 0.3386 - val_accuracy: 0.8853 - val_loss: 0.3024\n",
      "Epoch 22/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8937 - loss: 0.3180 - val_accuracy: 0.8775 - val_loss: 0.3046\n",
      "Epoch 23/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.8797 - loss: 0.3248 - val_accuracy: 0.8922 - val_loss: 0.2927\n",
      "Epoch 24/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8813 - loss: 0.3163 - val_accuracy: 0.8539 - val_loss: 0.3665\n",
      "Epoch 25/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8464 - loss: 0.3462 - val_accuracy: 0.8941 - val_loss: 0.2838\n",
      "Epoch 26/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8966 - loss: 0.3148 - val_accuracy: 0.8922 - val_loss: 0.2874\n",
      "Epoch 27/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.8935 - loss: 0.2713 - val_accuracy: 0.8961 - val_loss: 0.2812\n",
      "Epoch 28/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8913 - loss: 0.3156 - val_accuracy: 0.9078 - val_loss: 0.2699\n",
      "Epoch 29/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8742 - loss: 0.2658 - val_accuracy: 0.8794 - val_loss: 0.2896\n",
      "Epoch 30/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9258 - loss: 0.2297 - val_accuracy: 0.9108 - val_loss: 0.2644\n",
      "Epoch 31/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9249 - loss: 0.2542 - val_accuracy: 0.9069 - val_loss: 0.2638\n",
      "Epoch 32/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9168 - loss: 0.2544 - val_accuracy: 0.8980 - val_loss: 0.2669\n",
      "Epoch 33/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.8537 - loss: 0.3205 - val_accuracy: 0.9118 - val_loss: 0.2573\n",
      "Epoch 34/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9157 - loss: 0.2539 - val_accuracy: 0.9088 - val_loss: 0.2540\n",
      "Epoch 35/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.9001 - loss: 0.2962 - val_accuracy: 0.9137 - val_loss: 0.2509\n",
      "Epoch 36/100\n",
      "\u001b[1m 3/11\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8160 - loss: 0.4678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 12:31:08.729957: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 752ms/step - accuracy: 0.8438 - loss: 0.3988 - val_accuracy: 0.9127 - val_loss: 0.2495\n",
      "Epoch 37/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.8872 - loss: 0.2788 - val_accuracy: 0.9167 - val_loss: 0.2468\n",
      "Epoch 38/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.9455 - loss: 0.2211 - val_accuracy: 0.9157 - val_loss: 0.2463\n",
      "Epoch 39/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.8588 - loss: 0.2995 - val_accuracy: 0.9147 - val_loss: 0.2451\n",
      "Epoch 40/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.9218 - loss: 0.2543 - val_accuracy: 0.9157 - val_loss: 0.2405\n",
      "Epoch 41/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.8650 - loss: 0.3163 - val_accuracy: 0.9225 - val_loss: 0.2404\n",
      "Epoch 42/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.8950 - loss: 0.2803 - val_accuracy: 0.9108 - val_loss: 0.2533\n",
      "Epoch 43/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.8251 - loss: 0.3837 - val_accuracy: 0.9206 - val_loss: 0.2371\n",
      "Epoch 44/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.8389 - loss: 0.3250 - val_accuracy: 0.9098 - val_loss: 0.2425\n",
      "Epoch 45/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.8959 - loss: 0.2326 - val_accuracy: 0.9176 - val_loss: 0.2325\n",
      "Epoch 46/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 847ms/step - accuracy: 0.9207 - loss: 0.2555 - val_accuracy: 0.9206 - val_loss: 0.2286\n",
      "Epoch 47/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8795 - loss: 0.2421 - val_accuracy: 0.9225 - val_loss: 0.2278\n",
      "Epoch 48/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.9429 - loss: 0.2567 - val_accuracy: 0.9206 - val_loss: 0.2262\n",
      "Epoch 49/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.8658 - loss: 0.2839 - val_accuracy: 0.9275 - val_loss: 0.2246\n",
      "Epoch 50/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9153 - loss: 0.2227 - val_accuracy: 0.9206 - val_loss: 0.2262\n",
      "Epoch 51/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.9360 - loss: 0.2239 - val_accuracy: 0.9245 - val_loss: 0.2336\n",
      "Epoch 52/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.8922 - loss: 0.2415 - val_accuracy: 0.9186 - val_loss: 0.2198\n",
      "Epoch 53/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9429 - loss: 0.2364 - val_accuracy: 0.8951 - val_loss: 0.2683\n",
      "Epoch 54/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 750ms/step - accuracy: 0.8778 - loss: 0.2833 - val_accuracy: 0.9176 - val_loss: 0.2231\n",
      "Epoch 55/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.9199 - loss: 0.2290 - val_accuracy: 0.9294 - val_loss: 0.2165\n",
      "Epoch 56/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.9309 - loss: 0.2413 - val_accuracy: 0.9255 - val_loss: 0.2153\n",
      "Epoch 57/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9012 - loss: 0.2680 - val_accuracy: 0.9245 - val_loss: 0.2144\n",
      "Epoch 58/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9379 - loss: 0.2157 - val_accuracy: 0.9186 - val_loss: 0.2204\n",
      "Epoch 59/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 848ms/step - accuracy: 0.9358 - loss: 0.1839 - val_accuracy: 0.9235 - val_loss: 0.2121\n",
      "Epoch 60/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 842ms/step - accuracy: 0.9176 - loss: 0.2082 - val_accuracy: 0.9245 - val_loss: 0.2117\n",
      "Epoch 61/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9376 - loss: 0.2338 - val_accuracy: 0.9314 - val_loss: 0.2128\n",
      "Epoch 62/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9142 - loss: 0.2001 - val_accuracy: 0.9324 - val_loss: 0.2071\n",
      "Epoch 63/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.9610 - loss: 0.1593 - val_accuracy: 0.9108 - val_loss: 0.2292\n",
      "Epoch 64/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 843ms/step - accuracy: 0.9226 - loss: 0.2364 - val_accuracy: 0.9294 - val_loss: 0.2052\n",
      "Epoch 65/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 845ms/step - accuracy: 0.9034 - loss: 0.2503 - val_accuracy: 0.9235 - val_loss: 0.2094\n",
      "Epoch 66/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.9325 - loss: 0.2013 - val_accuracy: 0.9186 - val_loss: 0.2237\n",
      "Epoch 67/100\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.9147 - loss: 0.2112"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, Flatten\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, average_precision_score\n",
    "# Enable mixed precision training\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "clear_session()  # This frees the GPU memory, peventing training deadlock\n",
    "\n",
    "# Function to create directories\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "setz = ['metal','glass', 'trash', 'cardboard', 'paper', 'plastic']\n",
    "\n",
    "for setClass in [setz[2]]: #setz:\n",
    "    clear_session()\n",
    "    global classez\n",
    "    classez = [setClass, 'other']\n",
    "    # data path\n",
    "    global dataset_path\n",
    "    dataset_path = f'/app/data/Datasets/augmented_{classez[0]}_and_{classez[1]}'  # <- docker file path      # \"G:\\My Drive\\Datasets\\ \"\n",
    "    \n",
    "\n",
    "    tar = (224, 224)\n",
    "    batch = 16 # 16\n",
    "    #Split the dataset\n",
    "    # Create an ImageDataGenerator for each subset\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # 20% for validation\n",
    "\n",
    "    # Training data generator\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=tar,\n",
    "        batch_size=batch,\n",
    "        class_mode='binary',\n",
    "        seed=42,\n",
    "        subset='training')  # Set as training data\n",
    "\n",
    "    # Validation data generator\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=tar,\n",
    "        batch_size=batch,\n",
    "        class_mode='binary',\n",
    "        seed=42,\n",
    "        subset='validation')  # Set as validation data\n",
    "\n",
    "    # Create a separate ImageDataGenerator for test data\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Test data generator\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=tar,\n",
    "        batch_size=batch,\n",
    "        seed=42,\n",
    "        class_mode='binary')  # No subset for testing\n",
    "    \n",
    "   \n",
    "\n",
    "    # Paths to save splits\n",
    "    base_dir = f'/app/data/Datasets/augmented_{classez[0]}_and_{classez[1]}-split'  # \"G:\\My Drive\\Datasets\\Trashnet-resized-split\"\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    val_dir = os.path.join(base_dir, 'val')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "    create_dir(base_dir)\n",
    "    create_dir(train_dir)\n",
    "    create_dir(val_dir)\n",
    "    create_dir(test_dir)\n",
    "\n",
    "    for class_name in classez: #, 'cardboard', 'metal', 'paper', 'plastic', 'trash']:\n",
    "        # Create class directories\n",
    "        create_dir(os.path.join(train_dir, class_name))\n",
    "        create_dir(os.path.join(val_dir, class_name))\n",
    "        create_dir(os.path.join(test_dir, class_name))\n",
    "\n",
    "        # List all files in the class directory\n",
    "        class_files = os.listdir(os.path.join(dataset_path, class_name))\n",
    "        train_files, test_files = train_test_split(class_files, test_size=0.2, random_state=42)  # 20% for testing\n",
    "        train_files, val_files = train_test_split(train_files, test_size=0.25, random_state=42)  # 20% of remaining for validation (0.25 * 0.8 = 0.2)\n",
    "\n",
    "        # Copy files to respective directories\n",
    "        for file in train_files:\n",
    "            shutil.copy(os.path.join(dataset_path, class_name, file), os.path.join(train_dir, class_name, file))\n",
    "\n",
    "        for file in val_files:\n",
    "            shutil.copy(os.path.join(dataset_path, class_name, file), os.path.join(val_dir, class_name, file))\n",
    "\n",
    "        for file in test_files:\n",
    "            shutil.copy(os.path.join(dataset_path, class_name, file), os.path.join(test_dir, class_name, file))\n",
    "        \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=tar,\n",
    "    batch_size=batch,\n",
    "    seed=42,\n",
    "    class_mode='binary'\n",
    "    # ,color_mode='grayscale'\n",
    "    )\n",
    "\n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=tar,\n",
    "        batch_size=batch,\n",
    "        seed=42,\n",
    "        class_mode='binary'\n",
    "        # ,color_mode='grayscale'\n",
    "        )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=tar,\n",
    "        batch_size=batch,\n",
    "        seed=42,\n",
    "        class_mode='binary'\n",
    "        # ,color_mode='grayscale'\n",
    "        )\n",
    "\n",
    "    img_shape = (224,224,3)\n",
    "    img_size = tar\n",
    "    batch_size = batch #16 #32\n",
    "    num_classes = 2\n",
    "    log_file = '/app/data/code/log_final.csv'\n",
    "\n",
    "    # DenseNet201 # MobileNetV3 # EfficientNetB0\n",
    "    base_model = tf.keras.applications.DenseNet201(input_shape=img_shape,\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "\n",
    "    model_name = base_model.name #'EfficientNetB0' # 'DenseNet201' # 'MobileNetV2'\n",
    "    # print(model_name)\n",
    "\n",
    "    base_model.trainable = False\n",
    "    for layer in base_model.layers[-6:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    class AccuracyLogger(Callback):\n",
    "        def __init__(self,   log_file, model_name, img_shape, batch_size, num_classes):\n",
    "            super().__init__()\n",
    "            self.log_file = log_file\n",
    "            self.model_name = model_name\n",
    "            self.img_shape = img_shape\n",
    "            self.batch_size = batch_size\n",
    "            self.num_classes = num_classes\n",
    "            \n",
    "            # self.summary = summary\n",
    "\n",
    "            # Write model and dataset information at the beginning of the log file\n",
    "            with open(self.log_file, 'a') as f:\n",
    "                f.write(f\"\\nModel: {self.model_name}\\n\")\n",
    "                # f.write(f\"Model summary:{self.summary}\\n\")\n",
    "                f.write(f\"Image shape: {self.img_shape}\\n\")\n",
    "                f.write(f\"Batch size: {self.batch_size}\\n\")\n",
    "                f.write(f\"Dataset: {dataset_path}\\n\")\n",
    "                f.write(f\"Number of classes: {self.num_classes}\\n\\n\")\n",
    "                # f.write('Epoch,Accuracy,Validation Accuracy, Loss, Validation Loss\\n')\n",
    "                f.flush()\n",
    "\n",
    "        # def on_epoch_end(self, epoch, logs=None):\n",
    "        #     logs = logs or {}\n",
    "        #     accuracy = logs.get('accuracy')\n",
    "        #     val_accuracy = logs.get('val_accuracy')\n",
    "        #     loss = logs.get('loss')\n",
    "        #     val_loss = logs.get('val_loss')\n",
    "\n",
    "        #     # Write the epoch, accuracy, and validation accuracy to the log file\n",
    "        #     with open(self.log_file, 'a') as f:\n",
    "        #         f.write(f\"{epoch + 1},{accuracy},{val_accuracy},{loss},{val_loss}\\n\")\n",
    "        #         f.flush()\n",
    "\n",
    "    model = tf.keras.Sequential([base_model,\n",
    "                                #  tf.keras.layers.Flatten(),\n",
    "                                tf.keras.layers.GlobalAveragePooling2D(),\n",
    "                                #  tf.keras.layers.Dense(batch, activation=\"relu\"),\n",
    "                                tf.keras.layers.Dropout(0.2),\n",
    "                                tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "                                #  tf.keras.layers.Dense(2, activation=\"softmax\")\n",
    "                                ])\n",
    "\n",
    "    lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                    patience=2, \n",
    "                                    factor=0.3, #0.5,\n",
    "                                    verbose=1, \n",
    "                                    min_lr=0.01) #0.01)\n",
    "    model.compile(optimizer = 'sgd',\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "    #Train for 10 epochs\n",
    "    steps_per_epoch=int(len(train_generator)/batch_size)\n",
    "    validation_steps = validation_generator.samples // validation_generator.batch_size\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[AccuracyLogger(  log_file, model_name, img_shape, batch_size, num_classes),\n",
    "                    EarlyStopping(patience=5)],\n",
    "        epochs=100,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    def plot_graphs(history, batch_size):\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 5))  # 1 row, 2 columns\n",
    "\n",
    "        # Plot accuracy\n",
    "        axs[0].plot(history.history['accuracy'])\n",
    "        axs[0].plot(history.history['val_accuracy'])\n",
    "        axs[0].set_title(\"Model Accuracy\")\n",
    "        axs[0].set_xlabel(\"Epochs\")\n",
    "        axs[0].set_ylabel(\"Accuracy\")\n",
    "        axs[0].legend(['Train', 'Validation'])\n",
    "\n",
    "        # Plot loss\n",
    "        axs[1].plot(history.history['loss'])\n",
    "        axs[1].plot(history.history['val_loss'])\n",
    "        axs[1].set_title(\"Model Loss\")\n",
    "        axs[1].set_xlabel(\"Epochs\")\n",
    "        axs[1].set_ylabel(\"Loss\")\n",
    "        axs[1].legend(['Train', 'Validation'])\n",
    "\n",
    "        plt.tight_layout()  # Adjust layout to make sure plots don't overlap\n",
    "\n",
    "        # Ensure the save directory exists\n",
    "        save_dir = '/app/data/graphs/'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Create the filename using the dataset path and batch size\n",
    "        dataset_name = os.path.basename(dataset_path[29:])  # filter out '/app/data/Datasets/' \n",
    "        filename = f\"{dataset_name}_100epoch_batch{batch_size}_{model_name}.png\"\n",
    "\n",
    "        # Save the figure\n",
    "        save_path = os.path.join(save_dir, filename)\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Graph saved at: {save_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # plot\n",
    "    plot_graphs(history, batch)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_generator, verbose=False)\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true = test_generator.classes\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "    # Calculate mAP\n",
    "    # Note: This assumes binary classification. For multi-class, you'll need to modify this.\n",
    "    mAP = average_precision_score(y_true, y_pred)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "\n",
    "    # Log the metrics\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"Testing Accuracy: {accuracy:.4f}\\n\")\n",
    "        f.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        f.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        f.write(f\"F1 Score: {f1:.4f}\\n\")\n",
    "        f.write(f\"mAP: {mAP:.4f}\\n\")\n",
    "        f.flush()\n",
    "\n",
    "    # Plot and save confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f'{setClass[0]}confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Print metrics\n",
    "    # print(f\"Testing Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1 Score: {f1:.4f}\")\n",
    "    # print(f\"mAP: {mAP:.4f}\")\n",
    "    print(f\"Confusion Matrix saved as '{setClass[0]}confusion_matrix.png'\")\n",
    "\n",
    "    # Save model\n",
    "    model.save(f\"/app/data/{model_name}_{setClass[0]}.keras\")\n",
    "    print(f\"{setClass[0]} trained and tested successfully!\")\n",
    "print(\"Training complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
